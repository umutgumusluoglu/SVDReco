# -*- coding: utf-8 -*-
"""SVDReco.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17aV4taukLauG4J1iD7Y0XHkthKfLrbZu
"""

#!pip install scikit-surprise
#!pip uninstall -y numpy
#!pip install numpy==1.24.4
#!pip install scikit-surprise

import pandas as pd
from scipy.linalg import svd
#!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip
#!unzip ml-1m.zip

# ratings verisi
ratings = pd.read_csv("ml-1m/ratings.dat", sep="::", engine='python', names=["UserID", "MovieID", "Rating", "Timestamp"])

# movies verisi
movies = pd.read_csv("ml-1m/movies.dat", sep="::", engine='python', names=["MovieID", "Title", "Genres"], encoding='latin-1')

# users verisi
users = pd.read_csv("ml-1m/users.dat", sep="::", engine='python', names=["UserID", "Gender", "Age", "Occupation", "Zip-code"], encoding='latin-1')

ratings.head()

from surprise import Dataset, Reader, SVD

# Her kullanıcının kaç yorum yaptığını say
user_counts = ratings['UserID'].value_counts()

# Yalnızca 5 ve daha fazla yorum yapan kullanıcıları al
filtered_users = user_counts[user_counts >= 5].index

# Bu kullanıcıları ratings veri setinde filtrele
ratings_filtered = ratings[ratings['UserID'].isin(filtered_users)]

from surprise import SVD, Dataset, Reader, accuracy
from surprise.model_selection import train_test_split, cross_validate

# Modeli oluştur
model = SVD(n_factors=100, reg_all=0.1, lr_all=0.004)

# Reader ve veri hazırlığı
reader = Reader(rating_scale=(1, 5))
data_filtered = Dataset.load_from_df(ratings_filtered[['UserID', 'MovieID', 'Rating']], reader)

# Veri'nin %10'unu test yaptık
trainset, testset = train_test_split(data_filtered, test_size=0.1)
model.fit(trainset)

# Kullanıcılar için tahminler yap
all_movie_ids = ratings["MovieID"].unique()

for user_id in range(1, 11):
    watched = ratings[ratings["UserID"] == user_id]["MovieID"].tolist()
    unwatched = [m for m in all_movie_ids if m not in watched]

    predictions = []
    for movie_id in unwatched:
        pred = model.predict(user_id, movie_id)  # Tahmin yap
        predictions.append(pred)  # Prediction nesnesi ekle


# RMSE hesaplama (test verisi üzerinden)
rmse = accuracy.rmse(model.test(testset))  # Test verisi ile doğrulama
print(f"RMSE: {rmse}")

from surprise.model_selection import cross_validate

cv_results = cross_validate(model, data_filtered, measures=['RMSE', 'MAE'], cv=5, verbose=True)

print("Ortalama RMSE:", round(cv_results['test_rmse'].mean(), 4))

trainset = data_filtered.build_full_trainset()

# Modeli tanımla ve eğit

model.fit(trainset)

# Eğitim verisi üzerindeki tahminler


train_predictions = [
    model.predict(trainset.to_raw_uid(uid),
                  trainset.to_raw_iid(iid),
                  r_ui=r)
    for (uid, iid, r) in trainset.all_ratings()
]


# Eğitim RMSE'sini hesapla
train_rmse = accuracy.rmse(train_predictions)
print("Eğitim RMSE:", train_rmse)

from sklearn.metrics.pairwise import cosine_similarity


def compute_diversity(recommendation_df, movie_features):
    total_similarity = 0
    count = 0

    # Tüm kullanıcılar için
    for user_id in recommendation_df.index:
        recommended_movie_ids = recommendation_df.loc[user_id]

        # Bu filmlerin özelliklerini al
        features = movie_features.loc[recommended_movie_ids]

        # Cosine benzerliği hesapla
        sim_matrix = cosine_similarity(features)

        # Üst üçgeni (tekrarları ve diagonal dışı) al
        upper_tri_indices = np.triu_indices_from(sim_matrix, k=1)
        sims = sim_matrix[upper_tri_indices]

        # Ortalama benzerlik (çeşitliliğin tersi)
        total_similarity += sims.sum()
        count += len(sims)

    avg_similarity = total_similarity / count
    diversity = 1 - avg_similarity
    return diversity